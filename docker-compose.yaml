services:
  model-service:
    image: ghcr.io/remla25-team12/model-service:${TAG_MODEL_SERVICE:-latest}
    #image: ms-test:latest # local build, only for testing purposes
    container_name: model-service
    env_file: .env
    ports:
      - "${MODEL_SERVICE_PORT:-5000}:${MODEL_SERVICE_PORT:-5000}"
    environment:
      - MODEL_URL=https://github.com/remla25-team12/model-training/releases/download/v0.1.0/Classifier_Sentiment_Model.joblib # model URL
      - VEC_URL=https://github.com/remla25-team12/model-training/releases/download/v0.1.0/c1_BoW_Sentiment_Model.pkl # vectorizer URL
      - MODEL_CACHE_DIR=/app/cache
      - FEEDBACK_FILE_PATH=/app/feedback/feedback_dump.tsv
      - MODEL_SERVICE_PORT=${MODEL_SERVICE_PORT}
    # volumes:
    # - ./Classifier_Sentiment_Model.joblib:/app/Classifier_Sentiment_Model.joblib # local pre-downloaded model (prevent re-downloading)
    volumes:
      - cache:/app/cache # cache for downloaded models
      - ./feedback:/app/feedback
    networks:
      - backend
    restart: unless-stopped

  app:
    image: ghcr.io/remla25-team12/app:${TAG_APP:-latest}
    #image: app-test:latest # local build, only for testing purposes
    container_name: app
    env_file: .env
    ports:
      - 8080:5000
    environment:
      - MODEL_SERVICE_URL=http://model-service:${MODEL_SERVICE_PORT}/predict
      - NEW_DATA_URL=http://model-service:${MODEL_SERVICE_PORT}/new_data
      - VERSION_URL=http://model-service:${MODEL_SERVICE_PORT}/version
    networks:
      - backend
    restart: unless-stopped

networks:
  backend:
    driver: bridge

volumes:
  cache:
